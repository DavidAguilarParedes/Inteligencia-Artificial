{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTELIGENCIA ARTIFICIAL (INF 371)¶\n",
    "Dr. Edwin Villanueva (ervillanueva@pucp.edu.pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practica Guiada: Busqueda adversarial - juego  TicTacToe\n",
    "\n",
    "El presente notebook aborda el problema de busqueda adversarial en el juego de k-en-raya (generalizacón del 3 en raya pero en tableros de h filas por v columnas y gana el que haga primero una raya de tamaño k). El entorno de juego (clase TicTacToe) esta implementado. Estan implementados tambien los algoritmos MIN-MAX  y ALPHA-BETHA que pueden decidir movidas en el juego implementado.   \n",
    "\n",
    "Al final del notebook  responder a las preguntas planteadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase <b>Game</b>\n",
    "\n",
    "Esta es una clase genérica para definir un entorno de juego. Es parecida a la clase Problem de busqueda, pero con algunos cambios. No hay método que devuelve el costo de camino (no es relevante). Se tiene un metodo que devuelve la Utilidad de un jugador en un estado dado (estamos lidiando con agentes basados en utilidad). También la funcion test de objetivo es reemplazada por un test de estado terminal (terminal_test). Para crear una clase de un juego específico se debe hacer una subclase de Game e implementar los métodos actions, result, utility, and terminal_test. El atributo .initial (estado inicial del juego) deberá ser inicializado en el constructor de la clase concreta. No editar esta clase Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Retorna una lista de movidas permitidas en el estado actual state.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def result(self, state, move):\n",
    "        \"\"\"Retorna el nuevo estado que resulta de hacer una movida move en el estado state.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Retorna el valor de utilidad para el jugador player en el estado terminal state.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"Retorna True si el estado state es un estado terminal del juego.\"\"\"\n",
    "        return not self.actions(state)\n",
    "\n",
    "    def to_move(self, state):\n",
    "        \"\"\"Retorna el jugador que le toca jugar en el presente estado state.\"\"\"\n",
    "        return state.to_move\n",
    "\n",
    "    def display(self, state):\n",
    "        \"\"\"Imprime o displaya el state.\"\"\"\n",
    "        print(state)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{}>'.format(self.__class__.__name__)\n",
    "\n",
    "    def play_game(self, *players):\n",
    "        \"\"\"Controlador del juego:\n",
    "        Llama alternadamente a cada jugador pasandole el estado actual del juego y ejecutando la movida retornada.\"\"\"\n",
    "        state = self.initial\n",
    "        while True:\n",
    "            for player in players:\n",
    "                move = player(self, state)\n",
    "                state = self.result(state, move)\n",
    "                if self.terminal_test(state):\n",
    "                    self.display(state)\n",
    "                    return self.utility(state, self.to_move(self.initial)) #retorna utilidad del 1er jugador al acabar el juego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase <b>TicTacToe</b>\n",
    "\n",
    "Esta es una subclase de Game para definir el entorno del juego k en Raya (generalizacion de TicTacToe). Las dimensiones del tablero son seteadas en el constructor (h=numero de filas, v=numero de columnas, k=numero de elementos en raya para ganar). Primer jugador (Max) es 'X' y el otro jugador (Min) es 'O'. Un estado en este juego es una tupla (GameState) con los siguientes campos:\n",
    " - to_move: almacena el jugador que le toca jugar \n",
    " - utility: almacena la utilidad del estado\n",
    " - board: almacena las posiciones ocupadas en el tablero en la forma de un dicccionario de entradas {(x, y): Player}, donde Player puede ser 'X' o 'O'\n",
    " - moves: almacena las movidas posibles a partir del estado en la forma de lista de posiciones (x.y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "GameState = namedtuple('GameState', 'to_move, utility, board, moves') #Un estado es una tupla con nombres de campos (namedtuple)\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "class TicTacToe(Game):\n",
    "    \n",
    "    def __init__(self, h=3, v=3, k=3):\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "        self.k = k\n",
    "        moves = [(x, y) for x in range(1, h + 1)\n",
    "                 for y in range(1, v + 1)]\n",
    "        self.initial = GameState(to_move='X', utility=0, board={}, moves=moves)\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Movidas legales son todas las posiciones aun sin marcar (el estado almacena las movidas legales)\"\"\"\n",
    "        return state.moves\n",
    "\n",
    "    def result(self, state, move):\n",
    "        \"\"\"Retorna el nuevo estado de hacer la movida move en el estado state .\"\"\"\n",
    "        if move not in state.moves:\n",
    "            return state  # Si es una movida ilegal retorna sin cambiar el estado\n",
    "        board = state.board.copy()\n",
    "        board[move] = state.to_move\n",
    "        moves = list(state.moves)\n",
    "        moves.remove(move)\n",
    "        return GameState(to_move=('O' if state.to_move == 'X' else 'X'),\n",
    "                         utility=self.compute_utility(board, move, state.to_move),\n",
    "                         board=board, moves=moves)\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Retorna la utilidad del player en estado terminal state; 1 si ganó, -1 si perdió, 0 empate.\"\"\"\n",
    "        return state.utility if player == 'X' else -state.utility\n",
    "\n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"Un estado es terminal si hay un ganador o no hay mas movidas posibles.\"\"\"\n",
    "        return state.utility != 0 or len(state.moves) == 0\n",
    "\n",
    "    def display(self, state):\n",
    "        board = state.board\n",
    "        for x in range(1, self.h + 1):\n",
    "            for y in range(1, self.v + 1):\n",
    "                print(board.get((x, y), '.'), end=' ')\n",
    "            print()\n",
    "\n",
    "    def compute_utility(self, board, move, player):\n",
    "        \"\"\"Retorna 1 si player='X'  ha llegado a estado terminal ganador con movida move, \n",
    "           Retorna -1 si player='O' ha llegado a estado terminal ganador con movida move; \n",
    "           Retornas 0 en cualquier otro caso\"\"\"\n",
    "        if (self.k_in_row(board, move, player, (0, 1)) or\n",
    "                self.k_in_row(board, move, player, (1, 0)) or\n",
    "                self.k_in_row(board, move, player, (1, -1)) or\n",
    "                self.k_in_row(board, move, player, (1, 1))):\n",
    "            return +1 if player == 'X' else -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def k_in_row(self, board, move, player, delta_x_y):\n",
    "        \"\"\"Retorna true si hay una k-en-raya (k elementos en fila, columna o diagonal) \n",
    "           conteniendo la movida move del jugador player en el tablero board\"\"\"\n",
    "        (delta_x, delta_y) = delta_x_y\n",
    "        x, y = move\n",
    "        n = 0  # n is number of moves in row\n",
    "        while board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x + delta_x, y + delta_y\n",
    "        x, y = move\n",
    "        while board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x - delta_x, y - delta_y\n",
    "        n -= 1  # Because we counted move itself twice\n",
    "        return n >= self.k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo  <b>MIN-MAX</b>\n",
    "\n",
    "Este algoritmo escoge una movida para el jugador de turno en un juego dado (game). El algoritmo obtiene recursivamente los valores minimax de los estados sucesores buscando en profundidad en el arbol de juego los estados terminales. De estos estados toma su valor de utilidad para calcular la utilidad de los padres y asi sucesivamente hasta tener la utilidad de todos los sucesores del estado inicial para decidir la movida a ejecutar. \n",
    "La implementacion de esta busqueda es a traves de una recursion alternada de las funciones max_value y min_value (una llama a la otra) hasta alcanzar un estado terminal. Cuando la recursion termina todas las movidas tienen una utilidad y se escoje la movida de mayor valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = max\n",
    "infinity = float('inf')\n",
    "\n",
    "def minimax_decision(state, game):\n",
    "\n",
    "    player = game.to_move(state)\n",
    "\n",
    "    def max_value(state):\n",
    "        if game.terminal_test(state):\n",
    "            return game.utility(state, player)\n",
    "        v = -infinity\n",
    "        for a in game.actions(state):\n",
    "            v = max(v, min_value(game.result(state, a)))\n",
    "        return v\n",
    "\n",
    "    def min_value(state):\n",
    "        if game.terminal_test(state):\n",
    "            return game.utility(state, player)\n",
    "        v = infinity\n",
    "        for a in game.actions(state):\n",
    "            v = min(v, max_value(game.result(state, a)))\n",
    "        return v\n",
    "\n",
    "    # Body of minimax_decision:\n",
    "    return argmax(game.actions(state),\n",
    "                  key=lambda a: min_value(game.result(state, a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo  <b>ALPHA-BETA</b>\n",
    "\n",
    "Este algoritmo escoge una movida para el jugador de turno en el juego, evitando explorar las ramas que no son relevantes para tomar una decisión de movida en el estado actual. Alpha-Beta hace uso de las funciones max_value y min_value de MIN-MAX pero utilizando dos variables: alpha y betha. La variable apha mantiene la mejor opcion (la más alta utilidad) encontrada para MAX a lo largo del camino. La variable betha mantiene la mejor opcion (la más baja utilidad) encontrada para MIN. A medida que el algoritmo avanza se va actualizando alpha y betha y se poda un nodo cuando el valor del nodo es menor que el valor alpha (para MAX) o mayor que el valor betha (para MIN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta_search(state, game):\n",
    "  \n",
    "    player = game.to_move(state)\n",
    "\n",
    "    # Functions used by alphabeta\n",
    "    def max_value(state, alpha, beta):\n",
    "        if game.terminal_test(state):\n",
    "            return game.utility(state, player)\n",
    "        v = -infinity\n",
    "        for a in game.actions(state):\n",
    "            v = max(v, min_value(game.result(state, a), alpha, beta))\n",
    "            if v >= beta:\n",
    "                return v\n",
    "            alpha = max(alpha, v)\n",
    "        return v\n",
    "\n",
    "    def min_value(state, alpha, beta):\n",
    "        if game.terminal_test(state):\n",
    "            return game.utility(state, player)\n",
    "        v = infinity\n",
    "        for a in game.actions(state):\n",
    "            v = min(v, max_value(game.result(state, a), alpha, beta))\n",
    "            if v <= alpha:\n",
    "                return v\n",
    "            beta = min(beta, v)\n",
    "        return v\n",
    "\n",
    "    # Body of alphabeta_cutoff_search:\n",
    "    best_score = -infinity\n",
    "    beta = infinity\n",
    "    best_action = None\n",
    "    for a in game.actions(state):\n",
    "        v = min_value(game.result(state, a), best_score, beta)\n",
    "        if v > best_score:\n",
    "            best_score = v\n",
    "            best_action = a\n",
    "    return best_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Tree Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imlementa el nodo del arbol Monte carlo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCT_Node:\n",
    "    \"\"\"Node in the Monte Carlo search tree, keeps track of the children states.\"\"\"\n",
    "\n",
    "    def __init__(self, parent=None, state=None, U=0, N=0):\n",
    "        self.__dict__.update(parent=parent, state=state, U=U, N=N)\n",
    "        self.children = {}\n",
    "        self.actions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imlementa la funcion UCB1 para la fase de selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ucb(n, C=1.4):\n",
    "    if n.N == 0:\n",
    "        return np.inf    \n",
    "    else:\n",
    "        return (n.U / n.N) + C * np.sqrt(np.log(n.parent.N) / n.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmo Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_tree_search(state, game, N=1000):\n",
    "    def select(n):\n",
    "        \"\"\"select a leaf node in the tree\"\"\"\n",
    "        if n.children:\n",
    "            return select(max(n.children.keys(), key=ucb))\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def expand(n):\n",
    "        \"\"\"expand the leaf node by adding all its children states\"\"\"\n",
    "        if not n.children and not game.terminal_test(n.state):\n",
    "            n.children = {MCT_Node(state=game.result(n.state, action), parent=n): action\n",
    "                          for action in game.actions(n.state)}\n",
    "        return select(n)\n",
    "\n",
    "    def simulate(game, state):\n",
    "        \"\"\"simulate the utility of current state by random picking a step\"\"\"\n",
    "        player = game.to_move(state)\n",
    "        while not game.terminal_test(state):\n",
    "            action = random.choice(list(game.actions(state)))\n",
    "            state = game.result(state, action)\n",
    "        v = game.utility(state, player)\n",
    "        return -v\n",
    "\n",
    "    def backprop(n, utility):\n",
    "        \"\"\"passing the utility back to all parent nodes\"\"\"\n",
    "        if utility > 0:\n",
    "            n.U += utility\n",
    "        # if utility == 0:\n",
    "        #     n.U += 0.5\n",
    "        n.N += 1\n",
    "        if n.parent:\n",
    "            backprop(n.parent, -utility)\n",
    "\n",
    "    root = MCT_Node(state=state)\n",
    "\n",
    "    for _ in range(N):\n",
    "        leaf = select(root)\n",
    "        child = expand(leaf)\n",
    "        result = simulate(game, child.state)\n",
    "        backprop(child, result)\n",
    "\n",
    "    max_state = max(root.children, key=lambda p: p.N)\n",
    "\n",
    "    return root.children.get(max_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jugadores </b>\n",
    "\n",
    "A seguir se implementan 4 agentes jugadores que pueden hacer movidas en un entorno de juego, dado su estado :\n",
    "- <b>minimax_player</b>:   jugador con inteligencia MIN-MAX\n",
    "- <b>alphabeta_player</b>: jugador con inteligencia ALPHA-BETA \n",
    "- <b>random_player</b>:    jugador que hace movidas aleatorias (es facil ganarle :)\n",
    "- <b>human_player</b>:     solicita la movida a un humano\n",
    "- <b>mcts_player</b>:      jugador con inteligencia MCTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_player(game, state):\n",
    "    return minimax_decision(state, game)\n",
    "\n",
    "def alphabeta_player(game, state):\n",
    "    return alphabeta_search(state, game)\n",
    "\n",
    "def random_player(game, state):\n",
    "    return random.choice(game.actions(state))\n",
    "\n",
    "def human_player(game, state):\n",
    "    print(\"Estado actual:\")\n",
    "    game.display(state)\n",
    "    print(\"Movidas disponibles: {}\".format(game.actions(state)))\n",
    "    print(\"\")\n",
    "    move_string = input('Cuál es tu movida? ')\n",
    "    try:\n",
    "        move = eval(move_string)\n",
    "    except NameError:\n",
    "        move = move_string\n",
    "    return move\n",
    "\n",
    "def mcts_player(game, state):\n",
    "    return monte_carlo_tree_search(state, game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jugando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea el juego clasico 3 en raya y llama al controlador de juego. Primer jugador=minimax_player, Segundo jugador=random_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = TicTacToe(h=3, v=3, k=3)\n",
    "print(ttt.play_game(minimax_player, random_player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea el juego clasico 3 en raya y llama al controlador de juego. Primer jugador=alphabeta_player, Segundo jugador=random_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = TicTacToe(h=3, v=3, k=3)\n",
    "print(ttt.play_game(alphabeta_player, random_player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea el juego 3 en raya en tablero de 4x4 y llama al controlador de juego. Primer jugador=alphabeta_player, Segundo jugador=human_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = TicTacToe(h=3, v=3, k=3)\n",
    "print(ttt.play_game(alphabeta_player, human_player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preguntas:\n",
    "\n",
    "\n",
    "1) <b>¿Porque el jugador alphabeta_player hace movidas mas rápidas que minimax_player? (solo aumentando una fila y columna al tablero notará una gran diferecia (h=4, v=4, k=3) )<b>\n",
    "    \n",
    "    \n",
    "2) <b> Probar el jugador que implementa MCTS. Corregir el codigo si es necesario </b>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
