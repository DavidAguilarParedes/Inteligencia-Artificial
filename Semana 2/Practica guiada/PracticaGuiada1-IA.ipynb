{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# INTELIGENCIA ARTIFICIAL (INF 371)\n",
    "Dr. Edwin Villanueva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica Guiada 1:  Entorno de Laberinto y Agente Reactivo\n",
    "\n",
    "En este notebook vamos a practicar la implementacion de un entorno de un laberinto y habilitar un agente reactivo en el mismo. Al final de este notebook estan las preguntas que deben ser respondidas. \n",
    "\n",
    "El laberinto es un leido de un archivo de texto que puede terner los siguientes caracteres:\n",
    "\n",
    "    '#': Indica que es una celda con obstaculo  (impasable) \n",
    "    '~': Indica que es una celda con agua (pasable, con costo 5)\n",
    "    ' ': Indica que es una celda vacia (passable con costo 1)\n",
    "    'S': Indica que es celda de Inicio\n",
    "    'G': Indicates que es celda Objetivo ( premio de 100 )\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para leer el laberinto de disco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>readMazeFromFile</b>  La funcion readMazeFromFile lee un archivo de disco que contiene un laberinto y retorna una matriz de celdas del laberinto leido (grid).    grid es una lista de listas, ejemplo: [['#','S',' '],['#',' ','G'],['~','#','~']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMazeFromFile(file):\n",
    "    fin = open(file)\n",
    "    lines = fin.read().splitlines()\n",
    "    grid = []\n",
    "    for line in lines: \n",
    "        grid.append(list(line))\n",
    "    return grid    # grid es una lista de lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>getLocCells:</b> La funcion getLocCells devuelve la localizacion de la celda inicial (S) y celda objetivo (G) en un grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocCells(grid):\n",
    "    numRows = len(grid)\n",
    "    numCols = len(grid[0])\n",
    "    for i in range(numRows):\n",
    "        for j in range(numCols):\n",
    "            if len(grid[i]) != numCols:\n",
    "                raise \"Grid no Rectangular\"\n",
    "            if grid[i][j] == 'S':\n",
    "                cell_S = (i,j)\n",
    "            if grid[i][j] == 'G':\n",
    "                cell_G = (i,j)\n",
    "                \n",
    "    if cell_S == None:\n",
    "        raise \"No hay celda de Inicio\"\n",
    "    if cell_G == None:\n",
    "        raise \"No hay celda Objetivo (G)\"\n",
    "        \n",
    "    return cell_S, cell_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Funciones para mostrar los resultados en el laberinto</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid2Str(grid):\n",
    "    \"\"\" Convierte un grid a un string para vizualizacion \"\"\"\n",
    "    numRows = len(grid)\n",
    "    numCols = len(grid[0])\n",
    "    strGrid = []\n",
    "    headerLine = ' ' + ('-' * (numCols)) + ' '\n",
    "    strGrid.append(headerLine)\n",
    "    for row in grid:\n",
    "        rowLine = '|' + ''.join(row) + '|'\n",
    "        strGrid.append(rowLine)\n",
    "    strGrid.append(headerLine)\n",
    "    return '\\n'.join(strGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAgent(grid, agent_location, agent_performance):\n",
    "    \"\"\" Muestra los resultados en el grid.   \"\"\"\n",
    "    grid_copy = []\n",
    "    for row in grid:\n",
    "        grid_copy.append([x for x in row]) \n",
    "    row,col = agent_location\n",
    "    grid_copy[row][col] = 'X' \n",
    "    print (grid2Str(grid_copy))\n",
    "    print ('Desempeño del agente = {}'.format(agent_performance))\n",
    "    print (\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion del Entorno  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase <b>Thing</b>\n",
    "\n",
    "  Esta clase generica representa cualquier objeto fisico que puede aparecer en un <b>Ambiente</b>. (No editar)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thing(object):\n",
    "\n",
    "    def is_alive(self):\n",
    "        \"\"\"Cosas 'vivas'deben retornar true.\"\"\"\n",
    "        return hasattr(self, 'alive') and self.alive\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Muestra el estado interno del agente. Subclases deben sobreescribir esto.\"\"\"\n",
    "        print(\"I don't know how to show_state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase <b>Environment</b>\n",
    "\n",
    "Esta clase abstracta representa un entorno de tareas. Clases de entornos reales heredan de esta. En un entorno tipicamente se necesitará implementar 2 cosas:\n",
    "<b>percept</b>, que define la percepción que el agente ve; y \n",
    "<b>execute_action</b>, que define los efectos de ejecutar una acción. \n",
    "El entorno mantiene una lista de .things y .agents (el cual es un subconjunto de .things). Cada elemento de .things tiene un slot .location. (No editar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return []  # List of classes that can go into environment\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Retorna la percepcion que el agente 'agent' ve en este punto.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"El agente 'agent' ejecuta una accion 'action' en el entorno.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Localización por defecto para colocar una nueva cosa sin localizacion especificada.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"Retorna True si no hay ningun agente vivo\"\"\"\n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Añade una cosa thing al entorno en la localizacion location. \n",
    "           Si thing es un programa de agente, crea un nuevo agente con ese programa.\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        assert thing not in self.things, \"No añade la misma cosa dos veces\"\n",
    "        \n",
    "        if location is not None:\n",
    "            thing.location = location \n",
    "        else:\n",
    "            #print('colocara localizacion por defecto')\n",
    "            self.default_location(thing)\n",
    "        self.things.append(thing)\n",
    "        if isinstance(thing, Agent):\n",
    "            thing.performance = 0\n",
    "            self.agents.append(thing)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Ejecuta un paso del entorno (llama a los programas de los agentes, obtiene sus acciones y las ejecuta). \"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Ejecuta steps pasos en el entorno.\"\"\"\n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                return\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase <b>MazeEnvironment</b>\n",
    "\n",
    "Esta clase implementa el entorno del laberinto. El estado percibido por un agente en este entorno corresponde a la tupla [grid, location]. Las acciones posibles para un agente son: 'N' (ir una celda al norte), 'S' (ir una celda al sur), 'W' (ir una celda al oeste), 'E' (ir una celda al este)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeEnvironment(Environment):\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        super().__init__()\n",
    "        self.grid = grid\n",
    "        self.numRows = len(grid)\n",
    "        self.numCols = len(grid[0])\n",
    "        self.startCell, self.goalCell = getLocCells(grid)\n",
    "        \n",
    "    def default_location(self, agent):\n",
    "        \"\"\"Coloca Localización por defecto a un agente sin localizacion especificada (en celda 'S').\"\"\"\n",
    "        agent.location = self.startCell\n",
    "        \n",
    "    def thing_classes(self):\n",
    "        return [Agent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Retorna el estado del ambiente (location)\"\"\"\n",
    "        return agent.location\n",
    "    \n",
    "    def __isValidLocation(self,location):\n",
    "        \"\"\" Retorna true si la localizacion dada corresponde a una celda no bloqueada valida \"\"\"\n",
    "        row,col = location\n",
    "        if row < 0 or row >= self.numRows:\n",
    "            return False\n",
    "        if col < 0 or col >= self.numCols:\n",
    "            return False\n",
    "        return not self.grid[row][col] == '#'       \n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Implementa el MAPA De TRANSICION: Cambia la posicion del agente de acuerdo a la accion solicitada \"\"\"\n",
    "        row,col = agent.location   # obtiene posicion actual del agente\n",
    "        \n",
    "        if action == 'N' and self.__isValidLocation((row-1, col)):\n",
    "            agent.location = (row-1, col)\n",
    "            agent.performance -= 1\n",
    "            if self.grid[row-1][col]== '~':\n",
    "                agent.performance -= 5\n",
    "            \n",
    "        elif action == 'S' and self.__isValidLocation((row+1, col)):\n",
    "            agent.location = (row+1, col)\n",
    "            agent.performance -= 1  \n",
    "            if self.grid[row+1][col]== '~':\n",
    "                agent.performance -= 5\n",
    "            \n",
    "        elif action == 'W' and self.__isValidLocation((row, col-1)):\n",
    "            agent.location = (row, col-1)\n",
    "            agent.performance -= 1\n",
    "            if self.grid[row][col-1]== '~':\n",
    "                agent.performance -= 5\n",
    "            \n",
    "        elif action == 'E' and self.__isValidLocation((row, col+1)):\n",
    "            agent.location = (row, col+1)\n",
    "            agent.performance -= 1\n",
    "            if self.grid[row][col+1]== '~':\n",
    "                agent.performance -= 5\n",
    "                        \n",
    "        if agent.location == self.goalCell: \n",
    "            agent.performance += 100     # suma 100 puntos al desempeño del agente cuando llega a celda objetivo \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion de un Agente Reactivo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clase <b>Agent</b>\n",
    "\n",
    "Un agente es una subclase de Thing con un slot obligatorio: <b>.program</b>, el cual almacena la funcion que implementa el <b>programa del agente</b>. Esta funcion debe tomar como argumento la <b>percepcion</b> del agente y debe retornar una <b>accion</b>. La definicion de Percepcion y Accion depende del ambiente de trabajo (environment) donde el agente existe. El agente tambien puede tener el slot <b>.performance</b>, que mide el desempeño del agente en su ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "\n",
    "class Agent(Thing):\n",
    "    def __init__(self, program=None):\n",
    "        self.alive = True\n",
    "        self.performance = 0\n",
    "        assert isinstance(program, collections.Callable)\n",
    "        self.program = program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Clase que implementa un Programa de Agente Reactivo para el entorno MazeEnvironment</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class MazeReactiveAgentProgram:\n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "        \n",
    "    def __call__(self, percept):\n",
    "        state = percept\n",
    "        print('Agente recibiendo percepcion de localizacion = {}'.format(state))\n",
    "        action = '' \n",
    "        actionList = ['N','W','E']\n",
    "        \n",
    "        if state != (0,0):\n",
    "            \n",
    "            if state[0] == 0: # si estamos en la fila  0 no se necesitará ir al sur ( caso más simple )\n",
    "                actionList.remove('N')\n",
    "                \n",
    "            if state[1] == 0: # si estamos en la columna 0\n",
    "                actionList.remove('W')  \n",
    "                \n",
    "            action = random.choice(actionList)\n",
    "            \n",
    "            \n",
    "#         if state == (2,4):\n",
    "#             action = 'N'\n",
    "#         if state == (1,4):\n",
    "#             action = 'N'\n",
    "#         if state == (0,4):\n",
    "#             action = 'W'\n",
    "#         if state == (0,3):\n",
    "#             action = 'W'\n",
    "#         if state == (0,2):\n",
    "#             action = 'W'\n",
    "#         if state == (0,1):\n",
    "#             action = 'W'\n",
    "        \n",
    "        return action "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando el agente en MazeEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ \n",
      "|G       ~~~#|\n",
      "|####~~~~~~~#|\n",
      "|~   S    ~~#|\n",
      "|## # #####~#|\n",
      "|#  #      ~#|\n",
      "|# ##### ####|\n",
      "|#       ~~~#|\n",
      "|## ### #####|\n",
      " ------------ \n"
     ]
    }
   ],
   "source": [
    "# Carga un laberinto de archivo en disco, instancia el entorno y visualiza el grid\n",
    "mazegrid = readMazeFromFile('maze.txt') \n",
    "e = MazeEnvironment(mazegrid)\n",
    "print(grid2Str(mazegrid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ \n",
      "|G       ~~~#|\n",
      "|####~~~~~~~#|\n",
      "|~   X    ~~#|\n",
      "|## # #####~#|\n",
      "|#  #      ~#|\n",
      "|# ##### ####|\n",
      "|#       ~~~#|\n",
      "|## ### #####|\n",
      " ------------ \n",
      "Desempeño del agente = 0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Crea un agente reactivo y lo añade al entorno del laberinto\n",
    "a = Agent( MazeReactiveAgentProgram (mazegrid) ) \n",
    "e.add_thing(a) \n",
    "\n",
    "showAgent (mazegrid, a.location, a.performance)   # Agente es mostrado como una X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente recibiendo percepcion de localizacion = (0, 1)\n",
      " ------------ \n",
      "|X       ~~~#|\n",
      "|####~~~~~~~#|\n",
      "|~   S    ~~#|\n",
      "|## # #####~#|\n",
      "|#  #      ~#|\n",
      "|# ##### ####|\n",
      "|#       ~~~#|\n",
      "|## ### #####|\n",
      " ------------ \n",
      "Desempeño del agente = 76\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta 1 pasos del ambiente \n",
    "e.run(1)\n",
    "showAgent (mazegrid, a.location, a.performance)  # Agente es mostrado como una X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) <b>Implemente correctamente la medida de desempeño segun los costos de las celdas dados al inicio de este notebook<b>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Se debe añadir el siguiente código en la clase MazeEnvironment:\n",
    "    if self.grid[row-1][col]== '~':\n",
    "          agent.performance -= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) <b>Reimplemente el programa reactivo para exhibr una mejor racionalidad en un  entorno general de laberinto<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La idea era analizar el caso más simple cuando el goal esté en la esquina para luego poder hacer un caso más general \n",
    "pero ya no pude implementarlo.\n",
    "\n",
    "# if state != (0,0):\n",
    "            \n",
    "#             if state[0] == 0: # si estamos en la fila  0 no se necesitará ir al sur ( caso más simple )\n",
    "#                 actionList.remove('N')\n",
    "                \n",
    "#             if state[1] == 0: # si estamos en la columna 0\n",
    "#                 actionList.remove('W')  \n",
    "                \n",
    "#             action = random.choice(actionList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "3) <b>Explique porqué un agente de resolucion de problemas seria mas racional en este entorno<b> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado que no tenemos un punto inicial del agente, este podría ir al norte y toparse con un bloque para luego no \n",
    "poder salir de un bucle infinito. Es por ello que se recomienda usar acciones aleatorias, pero en el caso \n",
    "de que el agente llegue al tope este se debería eliminar la accion de ir al este para poder \"forzar\" que busque una \n",
    "solución yendo al sentido contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) <b>Qué capacidades deberia tener el agente si el entorno es desconocido (no tiene acceso al grid)? (asumo que conoce el exit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente debe tener racionalidad para poder optimizar el desempeño de la busqueda porque debe de encontrar el camino \n",
    "más corto; debe de tener la capacidad de colectar información dado que no se conoce el laberinto ; y ,por último,\n",
    "debe de tener la capacidad de aprender pues en caso de que se tope con un camino sin salida no deberia de volver a este."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
