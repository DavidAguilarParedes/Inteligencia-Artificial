{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXwFDyxM1rQ8"
   },
   "source": [
    "# INTELIGENCIA ARTIFICIAL (INF 371)\n",
    "Dr. Edwin Villanueva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Laboratorio 2: Busqueda con Información y Heurísticas en el Entorno del 8-puzzle\n",
    "\n",
    "El presente laboratorio aborda la formulacion del problema de busqueda para el entorno de puzzle de 8 posiciones, asi como la implementación de heurísticas de búsqueda para la busqueda con A*. Se debe implementar la heurística de Distancia en Linea Recta (función <b>heuristic_distsStraightline()</b>) y la heurística de Distancia Manhattan (función <b>heuristic_distsStraightline()</b>). Al final del notebook se encuentran las preguntas que serán evaluadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbrDk0krJQFC"
   },
   "source": [
    "<font color='orange'>Entorno del 8-puzzle con heurísticas</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXMj_9uFjv5_"
   },
   "source": [
    "<img src='https://images-na.ssl-images-amazon.com/images/I/61x5wYJJtsL._SX425_.jpg' width=200px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txrpj8dRJYA9"
   },
   "source": [
    "## Definición de entornos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNtt3hqkjv6A"
   },
   "source": [
    "### Clase <b>Thing</b>\n",
    "\n",
    "  Esta clase generica representa cualquier objeto fisico que puede aparecer en un <b>Ambiente</b>. (No editar)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOj9i4tqjv6B"
   },
   "outputs": [],
   "source": [
    "class Thing(object):\n",
    "    def is_alive(self):\n",
    "        \"\"\"Cosas 'vivas'deben retornar true.\"\"\"\n",
    "        return hasattr(self, 'alive') and self.alive\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Muestra el estado interno del agente. Subclases deben sobreescribir esto.\"\"\"\n",
    "        print(\"I don't know how to show_state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmilZwfHjv6R"
   },
   "source": [
    "### Clase <b>Environment</b>\n",
    "\n",
    "Esta clase abstracta representa un entorno de tareas. Clases de entornos reales heredan de esta. En un entorno tipicamente se necesitará implementar 2 cosas:\n",
    "<b>percept</b>, que define la percepción que el agente ve; y \n",
    "<b>execute_action</b>, que define los efectos de ejecutar una acción. \n",
    "El entorno mantiene una lista de .things y .agents (el cual es un subconjunto de .things). Cada elemento de .things tiene un slot .location. (No editar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqo57JjAjv6S"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return []  # List of classes that can go into environment\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Retorna la percepcion que el agente 'agent' ve en este punto.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"El agente 'agent' ejecuta una accion 'action' en el entorno.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Localización por defecto para colocar una nueva cosa sin localizacion especificada.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"Retorna True si no hay ningun agente vivo\"\"\"\n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Añade una cosa thing al entorno en la localizacion location. \n",
    "           Si thing es un programa de agente, crea un nuevo agente con ese programa.\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        assert thing not in self.things, \"No añade la misma cosa dos veces\"\n",
    "        thing.location = location if location is not None else self.default_location(thing)\n",
    "        self.things.append(thing)\n",
    "        if isinstance(thing, Agent):\n",
    "            thing.performance = 0\n",
    "            self.agents.append(thing)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Ejecuta un paso del entorno (llama a los programas de los agentes, obtiene sus acciones y las ejecuta). \"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Ejecuta steps pasos en el entorno.\"\"\"\n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                return\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESHef9F4jv6X"
   },
   "source": [
    "### Clase <b>EightpuzzleEnvironment </b>\n",
    "\n",
    "En esta clase se implementa el entorno del 8-puzzle. Un agente en este entorno percibe el estado del entorno como  string de 9 caracteres: los tres primeros caracteres representan las posiciones de la fila de arriba,  los tres siguientes caracteres la fila del medio y los 3 ultimos caracteres las posiciones de abajo del puzzle. El caracter * representa la posición en blanco.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kP_Aq-YFjv6Z"
   },
   "outputs": [],
   "source": [
    "class EightpuzzleEnvironment(Environment):\n",
    "\n",
    "    def __init__(self, initial_state):\n",
    "        super().__init__()\n",
    "        self.status = initial_state\n",
    "        \n",
    "    def thing_classes(self):\n",
    "        return [EightpuzzleReflexAgent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Retorna el estado del ambiente (las piezas que estan en cada posicion)\"\"\"\n",
    "        return self.status\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Implementa el MAPA De TRANSICION: Cambia la posicion de las piezas de acuerdo a la accion solicitada del blanco; \n",
    "        Cada accion valida debe provocar una disminución de desempeño en 1 unidad \"\"\"\n",
    "        \n",
    "        state = list(self.status)\n",
    "        iblank = state.index('*')    # obtiene el indice del casillero en blanco (representado con *)\n",
    "        \n",
    "        if action == 'Right':\n",
    "            if (iblank != 2 and iblank != 5 and iblank != 8):\n",
    "                state[iblank], state[iblank+1] = state[iblank+1], state[iblank]\n",
    "                agent.performance -= 1\n",
    "                \n",
    "        elif action == 'Left':\n",
    "            if (iblank != 0 and iblank != 3 and iblank != 6):\n",
    "                state[iblank-1], state[iblank] = state[iblank], state[iblank-1]\n",
    "                agent.performance -= 1\n",
    "                \n",
    "        elif action == 'Up':\n",
    "            if (iblank > 2):\n",
    "                state[iblank-3], state[iblank] = state[iblank], state[iblank-3]\n",
    "                agent.performance -= 1\n",
    "                \n",
    "        elif action == 'Down':\n",
    "            if (iblank < 6):\n",
    "                state[iblank], state[iblank+3] = state[iblank+3], state[iblank]\n",
    "                agent.performance -= 1\n",
    "                \n",
    "        self.status = ''.join(state) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PC4mQsFjv6H"
   },
   "source": [
    "### Clase <b>Agent</b>\n",
    "\n",
    "Un agente es una subclase de Thing con un slot obligatorio: <b>.program</b>, el cual almacena la funcion que implementa el <b>programa del agente</b>. Esta funcion debe tomar como argumento la <b>percepcion</b> del agente y debe retornar una <b>accion</b>. La definicion de Percepcion y Accion depende del ambiente de trabajo (environment) donde el agente existe. El agente tambien puede tener el slot <b>.performance</b>, que guarda el desempeño del agente en su ambiente (desempeño visto desde el agente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5L-PUa7_jv6K"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "\n",
    "class Agent(Thing):\n",
    "    def __init__(self, program=None):\n",
    "        self.alive = True\n",
    "        self.performance = 0\n",
    "        assert isinstance(program, collections.Callable)\n",
    "        self.program = program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOrXewaqJh8V"
   },
   "source": [
    "## Algoritmos de Búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdMAlWKRjv6e"
   },
   "source": [
    "### Clase <b>SearchProblem</b>\n",
    "\n",
    "Esta es una clase abstracta para definir problemas de busqueda. Se debe hacer subclases que implementen los metodos de las acciones, resultados, test de objetivo y el costo de camino. Entonces se puede instanciar las subclases y resolverlos con varias funciones de busqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6d3Zp0eljv6f"
   },
   "outputs": [],
   "source": [
    "class SearchProblem(object):\n",
    "    def __init__(self, initial, goal=None):\n",
    "        \"\"\"Este constructor especifica el estado inicial y posiblemente el estado(s) objetivo(s),\n",
    "        La subclase puede añadir mas argumentos.\"\"\"\n",
    "        self.initial = initial\n",
    "        self.goal = goal\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Retorna las acciones que pueden ser ejecutadas en el estado dado.\n",
    "        El resultado es tipicamente una lista.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def result(self, state, action):\n",
    "        \"\"\"Retorna el estado que resulta de ejecutar la accion dada en el estado state.\n",
    "        La accion debe ser alguna de self.actions(state).\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def goal_test(self, state):\n",
    "        \"\"\"Retorna True si el estado pasado satisface el objetivo.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def path_cost(self, c, state1, action, state2):\n",
    "        \"\"\"Retorna el costo del camino de state2 viniendo de state1 con \n",
    "        la accion action, asumiendo un costo c para llegar hasta state1. \n",
    "        El metodo por defecto cuesta 1 para cada paso en el camino.\"\"\"\n",
    "        return c + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZskZP4gzjv6j"
   },
   "source": [
    "### <b> Clase EightpuzzleSearchProblem</b>  \n",
    "Esta es una subclase de SearchProblem donde se definira concretamente el problema de busqueda para el ambiente del 8-puzzle. Se necesita completar Actions (acciones disponibles para un estado dado) y result (que estado resulta de ejecutar una accion en un estado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeY908Nxjv6l"
   },
   "outputs": [],
   "source": [
    "class EightpuzzleSearchProblem(SearchProblem):\n",
    "    \n",
    "    def __init__(self, initial, goal):\n",
    "        \"\"\"El constructor recibe  el estado inicial y el estado objetivo\"\"\"\n",
    "        self.initial = initial\n",
    "        self.goal = goal\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Retorna las acciones ejecutables desde el estado state.\n",
    "        Por ejemplo, para el estado '*12345678' debe retornar: acciones = ['Down', 'Right']\"\"\"\n",
    "        acciones = []\n",
    "        iblank = state.index('*')    # obtiene el indice del casillero en blanco (representado con *) del estado\n",
    "        \n",
    "        if (iblank != 2 and iblank != 5 and iblank != 8):\n",
    "            acciones.append('Right')\n",
    "        if (iblank != 0 and iblank != 3 and iblank != 6):\n",
    "            acciones.append('Left')\n",
    "        if (iblank > 2):\n",
    "            acciones.append('Up')\n",
    "        if (iblank < 6):\n",
    "            acciones.append('Down')\n",
    "        \n",
    "        return acciones\n",
    "\n",
    "    def result(self, state, action):\n",
    "        \"\"\"Retorna el estado que resulta de ejecutar la accion action desde state.\n",
    "        La accion debe ser alguna de self.actions(state)\n",
    "        Por ejemplo, para  state='*12345678' y action='Right' debe retornar newState = '1*2345678' \"\"\"  \n",
    "        \n",
    "        iblank = state.index('*')    # obtiene el indice del casillero en blanco (representado con *) del estado\n",
    "        newState = list(state)          # copia state en una lista newState\n",
    "        \n",
    "       \n",
    "        if action == 'Right':\n",
    "            if (iblank != 2 and iblank != 5 and iblank != 8):\n",
    "                newState[iblank], newState[iblank+1] = state[iblank+1], state[iblank]\n",
    "                \n",
    "        elif action == 'Left':\n",
    "            if (iblank != 0 and iblank != 3 and iblank != 6):\n",
    "                newState[iblank-1], newState[iblank] = state[iblank], state[iblank-1]\n",
    "                \n",
    "        elif action == 'Up':\n",
    "            if (iblank > 2):\n",
    "                newState[iblank-3], newState[iblank] = state[iblank], state[iblank-3]\n",
    "                \n",
    "        elif action == 'Down':\n",
    "            if (iblank < 6):\n",
    "                newState[iblank], newState[iblank+3] = state[iblank+3], state[iblank]\n",
    "\n",
    "        return ''.join(newState)\n",
    "        \n",
    "    def goal_test(self, state):\n",
    "        \"\"\"Retorna True si state es self.goal\"\"\"\n",
    "        return (self.goal == state) \n",
    "\n",
    "    def path_cost(self, c, state1, action, state2):\n",
    "        \"\"\"Retorna el costo del camino de state2 viniendo de state1 con la accion action \n",
    "        El costo del camino para llegar a state1 es c. El costo de la accion es = 1\"\"\"\n",
    "        return c + 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFUTPLbejv6q"
   },
   "source": [
    "### Clase <b>Node</b>\n",
    "\n",
    "Estructura de datos para almacenar la informacion de un nodo en un <b>arbol de busqueda</b>. Contiene información del nodo padre y el estado que representa el nodo. Tambien incluye la accion que nos llevo al presente nodo y el costo total del camino desde el nodo raiz hasta este nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrtAtMFGjv6s"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        \"Crea un nodo de arbol de busqueda, derivado del nodo parent y accion action\"\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.path_cost = path_cost\n",
    "        self.depth = 0\n",
    "        if parent:\n",
    "            self.depth = parent.depth + 1\n",
    "\n",
    "    def expand(self, problem):\n",
    "        \"Devuelve los nodos alcanzables en un paso a partir de este nodo.\"\n",
    "        return [self.child_node(problem, action)\n",
    "                for action in problem.actions(self.state)]\n",
    "\n",
    "    def child_node(self, problem, action):\n",
    "        next = problem.result(self.state, action)\n",
    "        return Node(next, self, action,\n",
    "                    problem.path_cost(self.path_cost, self.state, action, next))\n",
    "\n",
    "    def solution(self):\n",
    "        \"Retorna la secuencia de acciones para ir de la raiz a este nodo.\"\n",
    "        return [node.action for node in self.path()[1:]]\n",
    "\n",
    "    def path(self):\n",
    "        \"Retorna una lista de nodos formando un camino de la raiz a este nodo.\"\n",
    "        node, path_back = self, []\n",
    "        while node:\n",
    "            path_back.append(node)\n",
    "            node = node.parent\n",
    "        return list(reversed(path_back))\n",
    "    \n",
    "    def __lt__(self, node):\n",
    "        return self.state < node.state\n",
    "    \n",
    "    def __eq__(self, other): \n",
    "        \"Este metodo se ejecuta cuando se compara nodos. Devuelve True cuando los estados son iguales\"\n",
    "        return isinstance(other, Node) and self.state == other.state\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Node {}>\".format(self.state)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOPV8NLVjv6z"
   },
   "source": [
    "### <b> Define una cola tipo FIFO First-In-First-Out (para BFS)</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_r1BuSijv60"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FIFOQueue(deque):\n",
    "    \"\"\"Una cola First-In-First-Out\"\"\"\n",
    "    def pop(self):\n",
    "        return self.popleft()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvbNFBvCjv68"
   },
   "source": [
    "### <b> Frontera tipo cola de prioridad ordenada por una funcion de costo (para best_first_graph_search)</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbvZylPrjv69"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "class FrontierPQ:\n",
    "    \"Una Frontera ordenada por una funcion de costo (Priority Queue)\"\n",
    "    \n",
    "    def __init__(self, initial, costfn=lambda node: node.path_cost):\n",
    "        \"Inicializa la Frontera con un nodo inicial y una funcion de costo especificada (por defecto es el costo de camino).\"\n",
    "        self.heap   = []\n",
    "        self.states = {}\n",
    "        self.costfn = costfn\n",
    "        self.add(initial)\n",
    "    \n",
    "    def add(self, node):\n",
    "        \"Agrega un nodo a la frontera.\"\n",
    "        cost = self.costfn(node)\n",
    "        heapq.heappush(self.heap, (cost, node))\n",
    "        self.states[node.state] = node\n",
    "        \n",
    "    def pop(self):\n",
    "        \"Remueve y retorna el nodo con minimo costo.\"\n",
    "        (cost, node) = heapq.heappop(self.heap)\n",
    "        self.states.pop(node.state, None) # remove state\n",
    "        return node\n",
    "    \n",
    "    def replace(self, node):\n",
    "        \"node reemplaza al nodo de la Fontera que tiene el mismo estado que node.\"\n",
    "        if node.state not in self:\n",
    "            raise ValueError('{} no tiene nada que reemplazar'.format(node.state))\n",
    "        for (i, (cost, old_node)) in enumerate(self.heap):\n",
    "            if old_node.state == node.state:\n",
    "                self.heap[i] = (self.costfn(node), node)\n",
    "                heapq._siftdown(self.heap, 0, i)\n",
    "                return\n",
    "\n",
    "    def __contains__(self, state): return state in self.states\n",
    "    \n",
    "    def __len__(self): return len(self.heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WFNLAukmjv7B"
   },
   "source": [
    "### <b>Algoritmo general de búsqueda con memoria de nodos expandidos (Graph Search)</b>\n",
    "\n",
    "Algoritmo de general de busqueda ciega con memoria de estados visitados. El argumento frontier debe ser una cola vacia. Si  frontier es tipo FIFO hace busqueda en amplitud (BFS), si la frontier es una pila hará busqueda en profundidad (DFS). Devuelve el nodo solucion y una lista de nodos visitados durante la busqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf0L3tGejv7D"
   },
   "outputs": [],
   "source": [
    "def graph_search(problem, frontier):\n",
    "    frontier.append(Node(problem.initial))\n",
    "    explored = set()     # memoria de estados visitados\n",
    "    visited_nodes = []   # almacena nodos visitados durante la busqueda\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        visited_nodes.append(node)\n",
    "        if problem.goal_test(node.state):\n",
    "            return node, visited_nodes\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        frontier.extend(child for child in node.expand(problem)\n",
    "                        if child.state not in explored and\n",
    "                        child not in frontier)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Khv15QAhjv7H"
   },
   "source": [
    "### <b> Algoritmo de Busqueda por la mejor opción (Best-First-Graph-Search) </b> \n",
    "Algoritmo general de busqueda con información. La frontera es una cola de prioridad ordenada por la funcion de evaluacion f. Devuelve el nodo solucion y una lista de nodos visitados durante la busqueda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YZGQ6SWjv7J"
   },
   "outputs": [],
   "source": [
    "def best_first_graph_search(problem, f):\n",
    "    \"\"\"Busca el objetivo expandiendo el nodo de la frontera con el menor valor de la funcion f. Memoriza estados visitados\n",
    "    Antes de llamar a este algoritmo hay que especificar La funcion f(node). Si f es node.depth tenemos Busqueda en Amplitud; \n",
    "    si f es node.path_cost tenemos Busqueda  de Costo Uniforme. Si f es una heurística tenemos Busqueda Voraz;\n",
    "    Si f es node.path_cost + heuristica(node) tenemos A* \"\"\"\n",
    "\n",
    "    frontier = FrontierPQ( Node(problem.initial), f )  # frontera tipo cola de prioridad ordenada por f\n",
    "    explored = set()     # memoria de estados visitados\n",
    "    visited_nodes = []   # almacena nodos visitados durante la busqueda\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        visited_nodes.append(node)        \n",
    "        if problem.goal_test(node.state):\n",
    "            return node, visited_nodes\n",
    "        explored.add(node.state)\n",
    "        for action in problem.actions(node.state):\n",
    "            child = node.child_node(problem, action)\n",
    "            if child.state not in explored and child.state not in frontier:\n",
    "                frontier.add(child)\n",
    "            elif child.state in frontier:\n",
    "                incumbent = frontier.states[child.state] \n",
    "                if f(child) < f(incumbent):\n",
    "                    frontier.replace(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Algoritmo A* </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_search(problem, heuristic):\n",
    "    f = lambda node: node.path_cost + heuristic(node, problem)\n",
    "    return best_first_graph_search(problem, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion utilitaria que convierte un estado (string) a un arreglo 2D para computar heurísticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujedWEj7_drs"
   },
   "outputs": [],
   "source": [
    "def ConvertirStringde9EnArreglo2D(cadena9):\n",
    "  arr = []\n",
    "  for i in range(3):\n",
    "    fila = []\n",
    "    for j in range(3):\n",
    "      fila.append(cadena9[3*i+j])\n",
    "    arr.append(fila)\n",
    "  return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1160,
     "status": "ok",
     "timestamp": 1570901200115,
     "user": {
      "displayName": "Daniel Saromo Mori",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCOK2ChjoIib2lRINo4ABgUlyeG_mV_-Vsxl4MM5w=s64",
      "userId": "14692090418636087884"
     },
     "user_tz": 300
    },
    "id": "UOAE-yilAc1u",
    "outputId": "27d79936-7bee-4516-d399-394e3e2f1663"
   },
   "outputs": [],
   "source": [
    "estado = ConvertirStringde9EnArreglo2D('31264578*')\n",
    "objetivo = ConvertirStringde9EnArreglo2D('*12345678') \n",
    "print(estado)\n",
    "print(objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estado = ConvertirStringde9EnArreglo2D('31264578*')\n",
    "objetivo = ConvertirStringde9EnArreglo2D('*12345678') \n",
    "\n",
    "x = 0\n",
    "y = 0 \n",
    "diccionario_estado = {}\n",
    "for s in estado:\n",
    "    for element in s:\n",
    "        y = s.index(element)        \n",
    "        coordenada = [x,y]\n",
    "        if element =='*':\n",
    "            element = 9\n",
    "        diccionario_estado[int(element)] = coordenada\n",
    "    x += 1\n",
    "\n",
    "#####################################\n",
    "x = 0\n",
    "y = 0\n",
    "diccionario_obj = {}\n",
    "for s in objetivo:\n",
    "    for element in s:\n",
    "        y = s.index(element)        \n",
    "        coordenada = [x,y]\n",
    "        if element =='*':\n",
    "            element = 9\n",
    "        diccionario_obj[int(element)] = coordenada\n",
    "    x += 1\n",
    "print(diccionario_estado)\n",
    "#rint(diccionario_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "for i in range(9):    \n",
    "    a = diccionario_estado[x]\n",
    "    b = diccionario_obj[x]\n",
    "    delta_x = a[0] - b[0]\n",
    "    x += 1\n",
    "    print(a,b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetivo = ConvertirStringde9EnArreglo2D('*12345678')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iIIuRHTzjv7P"
   },
   "source": [
    "### <b> Heurísticas para A* </b> \n",
    "Se debe implementar las heurísticas abajo para A* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMyABFTAjv7Q"
   },
   "outputs": [],
   "source": [
    "#Para elevar un número a una potencia, se sugiere usar la libreria math\n",
    "import math\n",
    "math.pow(4,2)\n",
    "\n",
    "def nullheuristic(node, problem):\n",
    "    \"\"\"heurística nula (A* se convierte en busqueda de costo uniforme)\"\"\"\n",
    "    return 0\n",
    "\n",
    "def heuristic_numMissplaced(node, problem):\n",
    "    \"\"\"Heurística que cuenta cantidad de piezas fuera de lugar\"\"\"\n",
    "    cant_missplaced = 0\n",
    "    for i in range( len(problem.goal) ):\n",
    "        if(node.state[i] != problem.goal[i]):\n",
    "            cant_missplaced = cant_missplaced+1 \n",
    "    return cant_missplaced\n",
    "\n",
    "def heuristic_distsManhattan(node, problem):\n",
    "    \"\"\"Heurística que suma las distancias manhattan de cada una de las piezas hasta\n",
    "    su respectiva posición objetivo\"\"\"\n",
    "    #Sugerencia, convertir las cadenas a arreglos 2D\n",
    "    estado = ConvertirStringde9EnArreglo2D(node.state)\n",
    "    objetivo = ConvertirStringde9EnArreglo2D(problem.goal) \n",
    "    \n",
    "    x = 0\n",
    "    y = 0 \n",
    "    diccionario_estado = {}\n",
    "    for s in estado:\n",
    "        for element in s:\n",
    "            y = s.index(element)        \n",
    "            coordenada = [x,y]\n",
    "            if element =='*':\n",
    "                element = 10\n",
    "            diccionario_estado[int(element)] = coordenada\n",
    "        x += 1\n",
    "        \n",
    "    #####################################\n",
    "    x = 0\n",
    "    y = 0\n",
    "    diccionario_obj = {}\n",
    "    for s in objetivo:\n",
    "        for element in s:\n",
    "            y = s.index(element)        \n",
    "            coordenada = [x,y]\n",
    "            if element =='*':\n",
    "                element = 9\n",
    "            diccionario_obj[int(element)] = coordenada\n",
    "        x += 1\n",
    "        \n",
    "    \n",
    "    #COMPLETAR CÓDIGO\n",
    "    x = 1\n",
    "    for i in range(8):    \n",
    "        a = diccionario_estado[x]\n",
    "        b = diccionario_obj[x]\n",
    "        delta_x = a[0] - b[0]\n",
    "        delta_y = a[1] - b[1]\n",
    "        x += 1\n",
    "    return  abs(delta_x) + abs(delta_y) \n",
    "\n",
    "def heuristic_distsStraightline(node, problem):\n",
    "    \"\"\"Heurística que suma las distancias en línea recta de cada una de las piezas\n",
    "    hasta su respectiva posición objetivo\"\"\"\n",
    "    #Sugerencia, convertir las cadenas a arreglos 2D\n",
    "    estado = ConvertirStringde9EnArreglo2D(node.state)\n",
    "    objetivo = ConvertirStringde9EnArreglo2D(problem.goal)\n",
    "\n",
    "    \n",
    "    #COMPLETAR CÓDIGO\n",
    "\n",
    "    x = 0\n",
    "    y = 0 \n",
    "    diccionario_estado = {}\n",
    "    for s in estado:\n",
    "        for element in s:\n",
    "            y = s.index(element)        \n",
    "            coordenada = [x,y]\n",
    "            if element =='*':\n",
    "                element = 10\n",
    "            diccionario_estado[int(element)] = coordenada\n",
    "        x += 1\n",
    "        \n",
    "    #####################################\n",
    "    x = 0\n",
    "    y = 0\n",
    "    diccionario_obj = {}\n",
    "    for s in objetivo:\n",
    "        for element in s:\n",
    "            y = s.index(element)        \n",
    "            coordenada = [x,y]\n",
    "            if element =='*':\n",
    "                element = 9\n",
    "            diccionario_obj[int(element)] = coordenada\n",
    "        x += 1\n",
    "\n",
    "    x = 1\n",
    "    for i in range(8):    \n",
    "        a = diccionario_estado[x]\n",
    "        b = diccionario_obj[x]\n",
    "        delta_x = a[0] - b[0]\n",
    "        delta_y = a[1] - b[1]\n",
    "        x += 1\n",
    "    return math.sqrt( math.pow(delta_x, 2) + math.pow(delta_y, 2) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTmJT4I3jv7V"
   },
   "source": [
    "### <b>Clase que implementa el programa del agente que busca y ejecuta soluciones en el entorno 8-puzzle</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aogIcb-Tjv7W"
   },
   "outputs": [],
   "source": [
    "class EightpuzzleSearchProgram:\n",
    "    def __init__(self, goal_state, search_method):\n",
    "        self.goal = goal_state\n",
    "        self.method = search_method\n",
    "        self.seq = []  # lista de acciones a ejecutar, inicialmente vacia\n",
    "        \n",
    "    def __call__(self, percept):\n",
    "        state = percept\n",
    "        if state == self.goal:    # Si el ambiente esta en el estado objetivo no hace nada\n",
    "            return 'None'\n",
    "        if not self.seq:  # si la lista de acciones esta vacia\n",
    "            print('Agente buscara solucion al 8-puzzle: estado_inicial = {}. estado_objetivo={}'.format(state,self.goal))\n",
    "            search_problem = EightpuzzleSearchProblem(state, self.goal)\n",
    "            if self.method == 'bfs':\n",
    "                goal_node, visited_nodes = graph_search(search_problem, FIFOQueue()) # frontera es una cola FIFO  \n",
    "            elif self.method == 'dfs':\n",
    "                goal_node, visited_nodes = graph_search(search_problem, []) # frontera es una pila ([] es una pila en Python)\n",
    "            elif self.method == 'ucs':   # uniform cost search\n",
    "                goal_node, visited_nodes = astar_search(search_problem, nullheuristic)\n",
    "            elif self.method == 'astar_heuristic_numMissplaced':   # Heuristica heuristic_numMissplaced\n",
    "                goal_node, visited_nodes = astar_search(search_problem, heuristic_numMissplaced)\n",
    "            elif self.method == 'astar_heuristic_distsStraightline':   # Heuristica heuristic_distsStraightline\n",
    "                goal_node, visited_nodes = astar_search(search_problem, heuristic_distsStraightline)\n",
    "            elif self.method == 'astar_heuristic_heuristic_distsManhattan':   # Heuristica heuristic_distsManhattan\n",
    "                goal_node, visited_nodes = astar_search(search_problem, heuristic_distsManhattan)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                        \n",
    "            if goal_node == None: # sin solucion\n",
    "                print('No se encontro solucion para el 8-puzzle con metodo {}'.format(self.method) )\n",
    "                return 'None'\n",
    "            \n",
    "            self.seq = goal_node.solution()\n",
    "            print('Agente planeo una solucion al 8-puzzle con {}: Seq = {}. Nodos visitados={}. Costo Solucion = {}'.format(self.method, self.seq, len(visited_nodes),goal_node.path_cost)) \n",
    "        \n",
    "        action = self.seq.pop(0)       \n",
    "        return action "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOcwUxY6jv7a"
   },
   "source": [
    "### Probando el entorno 8-puzzle y agente de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2000,
     "status": "ok",
     "timestamp": 1570900886098,
     "user": {
      "displayName": "Daniel Saromo Mori",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCOK2ChjoIib2lRINo4ABgUlyeG_mV_-Vsxl4MM5w=s64",
      "userId": "14692090418636087884"
     },
     "user_tz": 300
    },
    "id": "nA_0J7Qjjv7c",
    "outputId": "b21b8e7a-270c-4c65-bb45-a5ef13402861"
   },
   "outputs": [],
   "source": [
    "\"\"\"Crea el entorno del 8-puzzle con estado inicial '' \"\"\"\n",
    "e = EightpuzzleEnvironment('31264578*')\n",
    "\n",
    "\"\"\"Crea un agente de busqueda para alcanzar goalstate\"\"\"\n",
    "goalstate = '*12345678'\n",
    "a = Agent( EightpuzzleSearchProgram (goalstate, 'bfs') )\n",
    "\n",
    "\"\"\"Añade el agente creado al entorno\"\"\"\n",
    "e.add_thing(a) \n",
    "\n",
    "# Ejecuta el entorno 25 pasos \n",
    "e.run(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1989,
     "status": "ok",
     "timestamp": 1570900886101,
     "user": {
      "displayName": "Daniel Saromo Mori",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCOK2ChjoIib2lRINo4ABgUlyeG_mV_-Vsxl4MM5w=s64",
      "userId": "14692090418636087884"
     },
     "user_tz": 300
    },
    "id": "2cYK6gaM-C-F",
    "outputId": "b72298b7-cb1a-42e2-e774-b2eabad9734d"
   },
   "outputs": [],
   "source": [
    "\"\"\"Crea el entorno del 8-puzzle con estado inicial '' \"\"\"\n",
    "e = EightpuzzleEnvironment('31264578*')\n",
    "\n",
    "\"\"\"Crea un agente de busqueda para alcanzar goalstate\"\"\"\n",
    "goalstate = '*12345678'\n",
    "a = Agent( EightpuzzleSearchProgram (goalstate, 'heuristic_distsManhattan') )\n",
    "\n",
    "\"\"\"Añade el agente creado al entorno\"\"\"\n",
    "e.add_thing(a) \n",
    "\n",
    "# Ejecuta el entorno 25 pasos \n",
    "e.run(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "JgkdcDtCjv7g"
   },
   "source": [
    "# Preguntas:\n",
    "\n",
    "\n",
    "<b>1) Implementar correctamente las heurísticas: heuristic_distsManhattan  y heuristic_distsStraightline  </b> (6 puntos)\n",
    "\n",
    "\n",
    "<b>2) Indique qué heurísticas son admisibles?  </b> (3 puntos)\n",
    "\n",
    "\n",
    "<b>3) Indique con cuál heurística se expande menos nodos para encontrar la solución (pruebe con diferentes estados iniciales)?  Justifique basado en la teoria </b> (3 puntos)\n",
    "\n",
    "\n",
    "<b>4) Indique si alguna heurística es dominante en general?  </b> (3 puntos)\n",
    "\n",
    "\n",
    "<b>5) En clase se vió 2 heurísticas para este problema haciendo relajamiento de las restricciones del problema (Problema relajado). Qué otra heurística puede obtener de esa forma y como implementaría su calculo? Seria mejor que las otras heurísticas? (5 puntos) </b> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   2) Una heurística admisible es aquella que nunca sobreestima el costo para poder llegar a la meta. En este caso , ambas heurísticas son admisibles pues el costo de la heuristica Manhatan, tomando como base la ley general de existencia de triangulos, jamás será mayor que la distancia recta. Asimismo Straight-line distance siempre será admisible porque el camino más corto siempre es la linea recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   3) La heurística de straightline_dist nos permite reducir la cantidad de nodos visitados porque se alejaban de nuestro punto objetivo mientras que la heurística manhatan_dist nos permite reducir aún más debido a que esta evita crear nodos hijos innecesarios que el straightline_dist si usaba.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) En este caso podemos decir que la heuristica Manhatan es la dominante porque es más eficiente ;asimismo porque, en el peor de los casos usando Manhatan ,se expandirá la cantidad de nodos usando linea recta.(Manhatan al tener mayores valores de h en cada nodo, expande nodos mas próximos del objetivo de que h1, significando menos nodos expandidos.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Podría implentarse la siguiente heurística:\n",
    "    c) Una pieza puede moverse desde el cuadrado A al B si es que B está vacío. Se tendría que implementar un código que permita mover las fichas al lugar que está vacio (*) intercambiando de lugar hasta que todas estén en su lugar correspndiente.En este caso podría ser mejor que la de la linea recta pero la Manhatan sería superior a esta ultima\n",
    "    El código podria ser como el siguiente:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recibimos el estado y objetivo\n",
    "estado = ConvertirStringde9EnArreglo2D(node.state)\n",
    "objetivo = ConvertirStringde9EnArreglo2D(problem.goal)\n",
    "\n",
    "\n",
    "\n",
    "#Obtenemos un diccionario con todas las posiciones\n",
    "\n",
    "x = 0\n",
    "y = 0 \n",
    "diccionario_estado = {}\n",
    "for s in estado:\n",
    "    for element in s:\n",
    "        y = s.index(element)        \n",
    "        coordenada = [x,y]\n",
    "        if element =='*':\n",
    "            element = 10\n",
    "        diccionario_estado[int(element)] = coordenada\n",
    "    x += 1\n",
    "\n",
    "#####################################\n",
    "x = 0\n",
    "y = 0\n",
    "diccionario_obj = {}\n",
    "for s in objetivo:\n",
    "    for element in s:\n",
    "        y = s.index(element)        \n",
    "        coordenada = [x,y]\n",
    "        if element =='*':\n",
    "            element = 9\n",
    "        diccionario_obj[int(element)] = coordenada\n",
    "    x += 1\n",
    "\n",
    "    \n",
    "x = 1\n",
    "for i in range(8):    \n",
    "    a = diccionario_estado[x] \n",
    "    aux2 = a\n",
    "    b = diccionario_obj[9]\n",
    "    delta_x = a[0] - b[0]\n",
    "    delta_y = a[1] - b[1]\n",
    "    x += 1\n",
    "    aux = math.sqrt( math.pow(delta_x, 2) + math.pow(delta_y, 2) ) \n",
    "    \n",
    "    #actualizamos los valores cambiados \n",
    "    #el valor actual cambiará\n",
    "    diccionario_estado[a] = b\n",
    "    diccionario_obj[9] = aux2 # cambiamos de lugares con el numero buscado\n",
    "    \n",
    "    return aux "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "txrpj8dRJYA9",
    "PNtt3hqkjv6A",
    "8PC4mQsFjv6H",
    "LmilZwfHjv6R",
    "ESHef9F4jv6X",
    "VdMAlWKRjv6e",
    "lOPV8NLVjv6z",
    "zvbNFBvCjv68",
    "WFNLAukmjv7B",
    "Khv15QAhjv7H",
    "YTmJT4I3jv7V",
    "ZskZP4gzjv6j"
   ],
   "name": "Sesion3_Ejemplo_8puzzle_Tarea.ipynb",
   "provenance": [
    {
     "file_id": "1OrveyMIg28QmtGL-h3W_xssTenV0Cw82",
     "timestamp": 1570298009228
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
